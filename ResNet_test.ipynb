{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJFf1HBTI3X0IYqzco00nB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FunkyDonkey065/Facade_aesthetic_evaluator/blob/main/ResNet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYjIprvG2lox",
        "outputId": "19a5481b-f48b-4acf-a4de-4da4cd00b839"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "   creating: data/51/\n",
            "  inflating: data/51/frame_3.jpg     \n",
            "  inflating: data/51/frame_2.jpg     \n",
            "  inflating: data/51/frame_2_score.json  \n",
            "  inflating: data/51/frame_1.jpg     \n",
            "   creating: data/52/\n",
            "  inflating: data/52/frame_3.jpg     \n",
            "  inflating: data/52/frame_2.jpg     \n",
            "  inflating: data/52/frame_2_score.json  \n",
            "  inflating: data/52/frame_1.jpg     \n",
            "   creating: data/24/\n",
            "  inflating: data/24/frame_3.jpg     \n",
            "  inflating: data/24/frame_2.jpg     \n",
            "  inflating: data/24/frame_2_score.json  \n",
            "  inflating: data/24/frame_1.jpg     \n",
            "   creating: data/22/\n",
            "  inflating: data/22/frame_3.jpg     \n",
            "  inflating: data/22/frame_2.jpg     \n",
            "  inflating: data/22/frame_2_score.json  \n",
            "  inflating: data/22/frame_1.jpg     \n",
            "   creating: data/41/\n",
            "  inflating: data/41/frame_3.jpg     \n",
            "  inflating: data/41/frame_2.jpg     \n",
            "  inflating: data/41/frame_2_score.json  \n",
            "  inflating: data/41/frame_1.jpg     \n",
            "   creating: data/30/\n",
            "  inflating: data/30/frame_3.jpg     \n",
            "  inflating: data/30/frame_2.jpg     \n",
            "  inflating: data/30/frame_2_score.json  \n",
            "  inflating: data/30/frame_1.jpg     \n",
            "   creating: data/6/\n",
            "  inflating: data/6/frame_3.jpg      \n",
            "  inflating: data/6/frame_2.jpg      \n",
            "  inflating: data/6/frame_2_score.json  \n",
            "  inflating: data/6/frame_1.jpg      \n",
            "   creating: data/60/\n",
            "  inflating: data/60/frame_3.jpg     \n",
            "  inflating: data/60/frame_2.jpg     \n",
            "  inflating: data/60/frame_2_score.json  \n",
            "  inflating: data/60/frame_1.jpg     \n",
            "   creating: data/25/\n",
            "  inflating: data/25/frame_3.jpg     \n",
            "  inflating: data/25/frame_2.jpg     \n",
            "  inflating: data/25/frame_2_score.json  \n",
            "  inflating: data/25/frame_1.jpg     \n",
            "   creating: data/72/\n",
            "  inflating: data/72/frame_3.jpg     \n",
            "  inflating: data/72/frame_2.jpg     \n",
            "  inflating: data/72/frame_2_score.json  \n",
            "  inflating: data/72/frame_1.jpg     \n",
            "   creating: data/1/\n",
            "  inflating: data/1/frame_3.jpg      \n",
            "  inflating: data/1/frame_2.jpg      \n",
            "  inflating: data/1/frame_2_score.json  \n",
            "  inflating: data/1/frame_1.jpg      \n",
            "   creating: data/37/\n",
            "  inflating: data/37/frame_3.jpg     \n",
            "  inflating: data/37/frame_2.jpg     \n",
            "  inflating: data/37/frame_2_score.json  \n",
            "  inflating: data/37/frame_1.jpg     \n",
            "   creating: data/11/\n",
            "  inflating: data/11/frame_3.jpg     \n",
            "  inflating: data/11/frame_2.jpg     \n",
            "  inflating: data/11/frame_2_score.json  \n",
            "  inflating: data/11/frame_1.jpg     \n",
            "   creating: data/80/\n",
            "  inflating: data/80/frame_3.jpg     \n",
            "  inflating: data/80/frame_2.jpg     \n",
            "  inflating: data/80/frame_2_score.json  \n",
            "  inflating: data/80/frame_1.jpg     \n",
            "   creating: data/38/\n",
            "  inflating: data/38/frame_3.jpg     \n",
            "  inflating: data/38/frame_2.jpg     \n",
            "  inflating: data/38/frame_2_score.json  \n",
            "  inflating: data/38/frame_1.jpg     \n",
            "   creating: data/56/\n",
            "  inflating: data/56/frame_3.jpg     \n",
            "  inflating: data/56/frame_2.jpg     \n",
            "  inflating: data/56/frame_2_score.json  \n",
            "  inflating: data/56/frame_1.jpg     \n",
            "   creating: data/91/\n",
            "  inflating: data/91/frame_3.jpg     \n",
            "  inflating: data/91/frame_2.jpg     \n",
            "  inflating: data/91/frame_2_score.json  \n",
            "  inflating: data/91/frame_1.jpg     \n",
            "   creating: data/84/\n",
            "  inflating: data/84/frame_3.jpg     \n",
            "  inflating: data/84/frame_2.jpg     \n",
            "  inflating: data/84/frame_2_score.json  \n",
            "  inflating: data/84/frame_1.jpg     \n",
            "   creating: data/23/\n",
            "  inflating: data/23/frame_3.jpg     \n",
            "  inflating: data/23/frame_2.jpg     \n",
            "  inflating: data/23/frame_2_score.json  \n",
            "  inflating: data/23/frame_1.jpg     \n",
            "   creating: data/63/\n",
            "  inflating: data/63/frame_3.jpg     \n",
            "  inflating: data/63/frame_2.jpg     \n",
            "  inflating: data/63/frame_2_score.json  \n",
            "  inflating: data/63/frame_1.jpg     \n",
            "   creating: data/5/\n",
            "  inflating: data/5/frame_3.jpg      \n",
            "  inflating: data/5/frame_2.jpg      \n",
            "  inflating: data/5/frame_2_score.json  \n",
            "  inflating: data/5/frame_1.jpg      \n",
            "   creating: data/86/\n",
            "  inflating: data/86/frame_3.jpg     \n",
            "  inflating: data/86/frame_2.jpg     \n",
            "  inflating: data/86/frame_2_score.json  \n",
            "  inflating: data/86/frame_1.jpg     \n",
            "   creating: data/4/\n",
            "  inflating: data/4/frame_3.jpg      \n",
            "  inflating: data/4/frame_2.jpg      \n",
            "  inflating: data/4/frame_2_score.json  \n",
            "  inflating: data/4/frame_1.jpg      \n",
            "   creating: data/53/\n",
            "  inflating: data/53/frame_3.jpg     \n",
            "  inflating: data/53/frame_2.jpg     \n",
            "  inflating: data/53/frame_2_score.json  \n",
            "  inflating: data/53/frame_1.jpg     \n",
            "   creating: data/99/\n",
            "  inflating: data/99/frame_3.jpg     \n",
            "  inflating: data/99/frame_2.jpg     \n",
            "  inflating: data/99/frame_2_score.json  \n",
            "  inflating: data/99/frame_1.jpg     \n",
            "   creating: data/10/\n",
            "  inflating: data/10/frame_3.jpg     \n",
            "  inflating: data/10/frame_2.jpg     \n",
            "  inflating: data/10/frame_2_score.json  \n",
            "  inflating: data/10/frame_1.jpg     \n",
            "   creating: data/71/\n",
            "  inflating: data/71/frame_3.jpg     \n",
            "  inflating: data/71/frame_2.jpg     \n",
            "  inflating: data/71/frame_2_score.json  \n",
            "  inflating: data/71/frame_1.jpg     \n",
            "   creating: data/75/\n",
            "  inflating: data/75/frame_3.jpg     \n",
            "  inflating: data/75/frame_2.jpg     \n",
            "  inflating: data/75/frame_2_score.json  \n",
            "  inflating: data/75/frame_1.jpg     \n",
            "   creating: data/7/\n",
            "  inflating: data/7/frame_3.jpg      \n",
            "  inflating: data/7/frame_2.jpg      \n",
            "  inflating: data/7/frame_2_score.json  \n",
            "  inflating: data/7/frame_1.jpg      \n",
            "   creating: data/33/\n",
            "  inflating: data/33/frame_3.jpg     \n",
            "  inflating: data/33/frame_2.jpg     \n",
            "  inflating: data/33/frame_2_score.json  \n",
            "  inflating: data/33/frame_1.jpg     \n",
            "   creating: data/49/\n",
            "  inflating: data/49/frame_3.jpg     \n",
            "  inflating: data/49/frame_2.jpg     \n",
            "  inflating: data/49/frame_2_score.json  \n",
            "  inflating: data/49/frame_1.jpg     \n",
            "   creating: data/8/\n",
            "  inflating: data/8/frame_3.jpg      \n",
            "  inflating: data/8/frame_2.jpg      \n",
            "  inflating: data/8/frame_2_score.json  \n",
            "  inflating: data/8/frame_1.jpg      \n",
            "   creating: data/88/\n",
            "  inflating: data/88/frame_3.jpg     \n",
            "  inflating: data/88/frame_2.jpg     \n",
            "  inflating: data/88/frame_2_score.json  \n",
            "  inflating: data/88/frame_1.jpg     \n",
            "   creating: data/68/\n",
            "  inflating: data/68/frame_3.jpg     \n",
            "  inflating: data/68/frame_2.jpg     \n",
            "  inflating: data/68/frame_2_score.json  \n",
            "  inflating: data/68/frame_1.jpg     \n",
            "   creating: data/69/\n",
            "  inflating: data/69/frame_3.jpg     \n",
            "  inflating: data/69/frame_2.jpg     \n",
            "  inflating: data/69/frame_2_score.json  \n",
            "  inflating: data/69/frame_1.jpg     \n",
            "   creating: data/77/\n",
            "  inflating: data/77/frame_3.jpg     \n",
            "  inflating: data/77/frame_2.jpg     \n",
            "  inflating: data/77/frame_2_score.json  \n",
            "  inflating: data/77/frame_1.jpg     \n",
            "   creating: data/2/\n",
            "  inflating: data/2/frame_3.jpg      \n",
            "  inflating: data/2/frame_2.jpg      \n",
            "  inflating: data/2/frame_2_score.json  \n",
            "  inflating: data/2/frame_1.jpg      \n",
            "   creating: data/64/\n",
            "  inflating: data/64/frame_3.jpg     \n",
            "  inflating: data/64/frame_2.jpg     \n",
            "  inflating: data/64/frame_2_score.json  \n",
            "  inflating: data/64/frame_1.jpg     \n",
            "   creating: data/87/\n",
            "  inflating: data/87/frame_3.jpg     \n",
            "  inflating: data/87/frame_2.jpg     \n",
            "  inflating: data/87/frame_2_score.json  \n",
            "  inflating: data/87/frame_1.jpg     \n",
            "   creating: data/40/\n",
            "  inflating: data/40/frame_3.jpg     \n",
            "  inflating: data/40/frame_2.jpg     \n",
            "  inflating: data/40/frame_2_score.json  \n",
            "  inflating: data/40/frame_1.jpg     \n",
            "   creating: data/58/\n",
            "  inflating: data/58/frame_3.jpg     \n",
            "  inflating: data/58/frame_2.jpg     \n",
            "  inflating: data/58/frame_2_score.json  \n",
            "  inflating: data/58/frame_1.jpg     \n",
            "   creating: data/65/\n",
            "  inflating: data/65/frame_3.jpg     \n",
            "  inflating: data/65/frame_2.jpg     \n",
            "  inflating: data/65/frame_2_score.json  \n",
            "  inflating: data/65/frame_1.jpg     \n",
            "   creating: data/85/\n",
            "  inflating: data/85/frame_3.jpg     \n",
            "  inflating: data/85/frame_2.jpg     \n",
            "  inflating: data/85/frame_2_score.json  \n",
            "  inflating: data/85/frame_1.jpg     \n",
            "   creating: data/94/\n",
            "  inflating: data/94/frame_3.jpg     \n",
            "  inflating: data/94/frame_2.jpg     \n",
            "  inflating: data/94/frame_2_score.json  \n",
            "  inflating: data/94/frame_1.jpg     \n",
            "   creating: data/67/\n",
            "  inflating: data/67/frame_3.jpg     \n",
            "  inflating: data/67/frame_2.jpg     \n",
            "  inflating: data/67/frame_2_score.json  \n",
            "  inflating: data/67/frame_1.jpg     \n",
            "   creating: data/17/\n",
            "  inflating: data/17/frame_3.jpg     \n",
            "  inflating: data/17/frame_2.jpg     \n",
            "  inflating: data/17/frame_2_score.json  \n",
            "  inflating: data/17/frame_1.jpg     \n",
            "   creating: data/34/\n",
            "  inflating: data/34/frame_3.jpg     \n",
            "  inflating: data/34/frame_2.jpg     \n",
            "  inflating: data/34/frame_2_score.json  \n",
            "  inflating: data/34/frame_1.jpg     \n",
            "   creating: data/48/\n",
            "  inflating: data/48/frame_3.jpg     \n",
            "  inflating: data/48/frame_2.jpg     \n",
            "  inflating: data/48/frame_2_score.json  \n",
            "  inflating: data/48/frame_1.jpg     \n",
            "   creating: data/19/\n",
            "  inflating: data/19/frame_3.jpg     \n",
            "  inflating: data/19/frame_2.jpg     \n",
            "  inflating: data/19/frame_2_score.json  \n",
            "  inflating: data/19/frame_1.jpg     \n",
            "   creating: data/31/\n",
            "  inflating: data/31/frame_3.jpg     \n",
            "  inflating: data/31/frame_2.jpg     \n",
            "  inflating: data/31/frame_2_score.json  \n",
            "  inflating: data/31/frame_1.jpg     \n",
            "   creating: data/20/\n",
            "  inflating: data/20/frame_3.jpg     \n",
            "  inflating: data/20/frame_2.jpg     \n",
            "  inflating: data/20/frame_2_score.json  \n",
            "  inflating: data/20/frame_1.jpg     \n",
            "   creating: data/46/\n",
            "  inflating: data/46/frame_3.jpg     \n",
            "  inflating: data/46/frame_2.jpg     \n",
            "  inflating: data/46/frame_2_score.json  \n",
            "  inflating: data/46/frame_1.jpg     \n",
            "   creating: data/98/\n",
            "  inflating: data/98/frame_3.jpg     \n",
            "  inflating: data/98/frame_2.jpg     \n",
            "  inflating: data/98/frame_2_score.json  \n",
            "  inflating: data/98/frame_1.jpg     \n",
            "   creating: data/47/\n",
            "  inflating: data/47/frame_3.jpg     \n",
            "  inflating: data/47/frame_2.jpg     \n",
            "  inflating: data/47/frame_2_score.json  \n",
            "  inflating: data/47/frame_1.jpg     \n",
            "   creating: data/81/\n",
            "  inflating: data/81/frame_3.jpg     \n",
            "  inflating: data/81/frame_2.jpg     \n",
            "  inflating: data/81/frame_2_score.json  \n",
            "  inflating: data/81/frame_1.jpg     \n",
            "   creating: data/39/\n",
            "  inflating: data/39/frame_3.jpg     \n",
            "  inflating: data/39/frame_2.jpg     \n",
            "  inflating: data/39/frame_2_score.json  \n",
            "  inflating: data/39/frame_1.jpg     \n",
            "   creating: data/13/\n",
            "  inflating: data/13/frame_3.jpg     \n",
            "  inflating: data/13/frame_2.jpg     \n",
            "  inflating: data/13/frame_2_score.json  \n",
            "  inflating: data/13/frame_1.jpg     \n",
            "   creating: data/83/\n",
            "  inflating: data/83/frame_3.jpg     \n",
            "  inflating: data/83/frame_2.jpg     \n",
            "  inflating: data/83/frame_2_score.json  \n",
            "  inflating: data/83/frame_1.jpg     \n",
            "   creating: data/97/\n",
            "  inflating: data/97/frame_3.jpg     \n",
            "  inflating: data/97/frame_2.jpg     \n",
            "  inflating: data/97/frame_2_score.json  \n",
            "  inflating: data/97/frame_1.jpg     \n",
            "   creating: data/76/\n",
            "  inflating: data/76/frame_3.jpg     \n",
            "  inflating: data/76/frame_2.jpg     \n",
            "  inflating: data/76/frame_2_score.json  \n",
            "  inflating: data/76/frame_1.jpg     \n",
            "   creating: data/57/\n",
            "  inflating: data/57/frame_3.jpg     \n",
            "  inflating: data/57/frame_2.jpg     \n",
            "  inflating: data/57/frame_2_score.json  \n",
            "  inflating: data/57/frame_1.jpg     \n",
            "   creating: data/79/\n",
            "  inflating: data/79/frame_3.jpg     \n",
            "  inflating: data/79/frame_2.jpg     \n",
            "  inflating: data/79/frame_2_score.json  \n",
            "  inflating: data/79/frame_1.jpg     \n",
            "   creating: data/78/\n",
            "  inflating: data/78/frame_3.jpg     \n",
            "  inflating: data/78/frame_2.jpg     \n",
            "  inflating: data/78/frame_2_score.json  \n",
            "  inflating: data/78/frame_1.jpg     \n",
            "   creating: data/18/\n",
            "  inflating: data/18/frame_3.jpg     \n",
            "  inflating: data/18/frame_2.jpg     \n",
            "  inflating: data/18/frame_2_score.json  \n",
            "  inflating: data/18/frame_1.jpg     \n",
            "   creating: data/26/\n",
            "  inflating: data/26/frame_3.jpg     \n",
            "  inflating: data/26/frame_2.jpg     \n",
            "  inflating: data/26/frame_2_score.json  \n",
            "  inflating: data/26/frame_1.jpg     \n",
            "   creating: data/92/\n",
            "  inflating: data/92/frame_3.jpg     \n",
            "  inflating: data/92/frame_2.jpg     \n",
            "  inflating: data/92/frame_2_score.json  \n",
            "  inflating: data/92/frame_1.jpg     \n",
            "   creating: data/66/\n",
            "  inflating: data/66/frame_3.jpg     \n",
            "  inflating: data/66/frame_2.jpg     \n",
            "  inflating: data/66/frame_2_score.json  \n",
            "  inflating: data/66/frame_1.jpg     \n",
            "   creating: data/43/\n",
            "  inflating: data/43/frame_3.jpg     \n",
            "  inflating: data/43/frame_2.jpg     \n",
            "  inflating: data/43/frame_2_score.json  \n",
            "  inflating: data/43/frame_1.jpg     \n",
            "   creating: data/36/\n",
            "  inflating: data/36/frame_3.jpg     \n",
            "  inflating: data/36/frame_2.jpg     \n",
            "  inflating: data/36/frame_2_score.json  \n",
            "  inflating: data/36/frame_1.jpg     \n",
            "   creating: data/28/\n",
            "  inflating: data/28/frame_3.jpg     \n",
            "  inflating: data/28/frame_2.jpg     \n",
            "  inflating: data/28/frame_2_score.json  \n",
            "  inflating: data/28/frame_1.jpg     \n",
            "   creating: data/21/\n",
            "  inflating: data/21/frame_3.jpg     \n",
            "  inflating: data/21/frame_2.jpg     \n",
            "  inflating: data/21/frame_2_score.json  \n",
            "  inflating: data/21/frame_1.jpg     \n",
            "   creating: data/96/\n",
            "  inflating: data/96/frame_3.jpg     \n",
            "  inflating: data/96/frame_2.jpg     \n",
            "  inflating: data/96/frame_2_score.json  \n",
            "  inflating: data/96/frame_1.jpg     \n",
            "   creating: data/9/\n",
            "  inflating: data/9/frame_3.jpg      \n",
            "  inflating: data/9/frame_2.jpg      \n",
            "  inflating: data/9/frame_1.jpg      \n",
            "   creating: data/0/\n",
            "  inflating: data/0/frame_3.jpg      \n",
            "  inflating: data/0/frame_2.jpg      \n",
            "  inflating: data/0/frame_2_score.json  \n",
            "  inflating: data/0/frame_1.jpg      \n",
            "   creating: data/16/\n",
            "  inflating: data/16/frame_3.jpg     \n",
            "  inflating: data/16/frame_2.jpg     \n",
            "  inflating: data/16/frame_2_score.json  \n",
            "  inflating: data/16/frame_1.jpg     \n",
            "   creating: data/82/\n",
            "  inflating: data/82/frame_3.jpg     \n",
            "  inflating: data/82/frame_2.jpg     \n",
            "  inflating: data/82/frame_2_score.json  \n",
            "  inflating: data/82/frame_1.jpg     \n",
            "   creating: data/15/\n",
            "  inflating: data/15/frame_3.jpg     \n",
            "  inflating: data/15/frame_2.jpg     \n",
            "  inflating: data/15/frame_2_score.json  \n",
            "  inflating: data/15/frame_1.jpg     \n",
            "   creating: data/29/\n",
            "  inflating: data/29/frame_3.jpg     \n",
            "  inflating: data/29/frame_2.jpg     \n",
            "  inflating: data/29/frame_2_score.json  \n",
            "  inflating: data/29/frame_1.jpg     \n",
            "   creating: data/35/\n",
            "  inflating: data/35/frame_3.jpg     \n",
            "  inflating: data/35/frame_2.jpg     \n",
            "  inflating: data/35/frame_2_score.json  \n",
            "  inflating: data/35/frame_1.jpg     \n",
            "   creating: data/14/\n",
            "  inflating: data/14/frame_3.jpg     \n",
            "  inflating: data/14/frame_2.jpg     \n",
            "  inflating: data/14/frame_2_score.json  \n",
            "  inflating: data/14/frame_1.jpg     \n",
            "   creating: data/90/\n",
            "  inflating: data/90/frame_3.jpg     \n",
            "  inflating: data/90/frame_2.jpg     \n",
            "  inflating: data/90/frame_2_score.json  \n",
            "  inflating: data/90/frame_1.jpg     \n",
            "   creating: data/45/\n",
            "  inflating: data/45/frame_3.jpg     \n",
            "  inflating: data/45/frame_2.jpg     \n",
            "  inflating: data/45/frame_2_score.json  \n",
            "  inflating: data/45/frame_1.jpg     \n",
            "   creating: data/3/\n",
            "  inflating: data/3/frame_3.jpg      \n",
            "  inflating: data/3/frame_2.jpg      \n",
            "  inflating: data/3/frame_2_score.json  \n",
            "  inflating: data/3/frame_1.jpg      \n",
            "   creating: data/55/\n",
            "  inflating: data/55/frame_3.jpg     \n",
            "  inflating: data/55/frame_2.jpg     \n",
            "  inflating: data/55/frame_2_score.json  \n",
            "  inflating: data/55/frame_1.jpg     \n",
            "   creating: data/27/\n",
            "  inflating: data/27/frame_3.jpg     \n",
            "  inflating: data/27/frame_2.jpg     \n",
            "  inflating: data/27/frame_2_score.json  \n",
            "  inflating: data/27/frame_1.jpg     \n",
            "   creating: data/93/\n",
            "  inflating: data/93/frame_3.jpg     \n",
            "  inflating: data/93/frame_2.jpg     \n",
            "  inflating: data/93/frame_2_score.json  \n",
            "  inflating: data/93/frame_1.jpg     \n",
            "   creating: data/74/\n",
            "  inflating: data/74/frame_3.jpg     \n",
            "  inflating: data/74/frame_2.jpg     \n",
            "  inflating: data/74/frame_2_score.json  \n",
            "  inflating: data/74/frame_1.jpg     \n",
            "   creating: data/62/\n",
            "  inflating: data/62/frame_3.jpg     \n",
            "  inflating: data/62/frame_2.jpg     \n",
            "  inflating: data/62/frame_2_score.json  \n",
            "  inflating: data/62/frame_1.jpg     \n",
            "   creating: data/95/\n",
            "  inflating: data/95/frame_3.jpg     \n",
            "  inflating: data/95/frame_2.jpg     \n",
            "  inflating: data/95/frame_2_score.json  \n",
            "  inflating: data/95/frame_1.jpg     \n",
            "   creating: data/12/\n",
            "  inflating: data/12/frame_3.jpg     \n",
            "  inflating: data/12/frame_2.jpg     \n",
            "  inflating: data/12/frame_2_score.json  \n",
            "  inflating: data/12/frame_1.jpg     \n",
            "   creating: data/54/\n",
            "  inflating: data/54/frame_3.jpg     \n",
            "  inflating: data/54/frame_2.jpg     \n",
            "  inflating: data/54/frame_2_score.json  \n",
            "  inflating: data/54/frame_1.jpg     \n",
            "   creating: data/44/\n",
            "  inflating: data/44/frame_3.jpg     \n",
            "  inflating: data/44/frame_2.jpg     \n",
            "  inflating: data/44/frame_2_score.json  \n",
            "  inflating: data/44/frame_1.jpg     \n",
            "   creating: data/61/\n",
            "  inflating: data/61/frame_3.jpg     \n",
            "  inflating: data/61/frame_2.jpg     \n",
            "  inflating: data/61/frame_2_score.json  \n",
            "  inflating: data/61/frame_1.jpg     \n",
            "   creating: data/42/\n",
            "  inflating: data/42/frame_3.jpg     \n",
            "  inflating: data/42/frame_2.jpg     \n",
            "  inflating: data/42/frame_2_score.json  \n",
            "  inflating: data/42/frame_1.jpg     \n",
            "   creating: data/59/\n",
            "  inflating: data/59/frame_3.jpg     \n",
            "  inflating: data/59/frame_2.jpg     \n",
            "  inflating: data/59/frame_2_score.json  \n",
            "  inflating: data/59/frame_1.jpg     \n",
            "   creating: data/73/\n",
            "  inflating: data/73/frame_3.jpg     \n",
            "  inflating: data/73/frame_2.jpg     \n",
            "  inflating: data/73/frame_2_score.json  \n",
            "  inflating: data/73/frame_1.jpg     \n",
            "   creating: data/50/\n",
            "  inflating: data/50/frame_3.jpg     \n",
            "  inflating: data/50/frame_2.jpg     \n",
            "  inflating: data/50/frame_2_score.json  \n",
            "  inflating: data/50/frame_1.jpg     \n",
            "   creating: data/70/\n",
            "  inflating: data/70/frame_3.jpg     \n",
            "  inflating: data/70/frame_2.jpg     \n",
            "  inflating: data/70/frame_2_score.json  \n",
            "  inflating: data/70/frame_1.jpg     \n",
            "   creating: data/89/\n",
            "  inflating: data/89/frame_3.jpg     \n",
            "  inflating: data/89/frame_2.jpg     \n",
            "  inflating: data/89/frame_2_score.json  \n",
            "  inflating: data/89/frame_1.jpg     \n",
            "   creating: data/32/\n",
            "  inflating: data/32/frame_3.jpg     \n",
            "  inflating: data/32/frame_2.jpg     \n",
            "  inflating: data/32/frame_2_score.json  \n",
            "  inflating: data/32/frame_1.jpg     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "527FHM8J1pjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qcbr5FkLt5pe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config"
      ],
      "metadata": {
        "id": "N814UYLy1xPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"data\"           # 如果在 /content/data 就改成 \"/content/data\"\n",
        "JSON_NAME = \"frame_2_score.json\"\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 4\n",
        "LR = 1e-4\n",
        "VAL_RATIO = 0.2\n",
        "NUM_WORKERS = 2  # Colab 可以设为 2, 本地可调大\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# 我们要从 JSON 中抽取的字段（8 维）\n",
        "LABEL_KEYS = [\n",
        "    (\"stimulus\", \"composition_and_proportion\"),\n",
        "    (\"stimulus\", \"material_and_details\"),\n",
        "    (\"stimulus\", \"color_harmony\"),\n",
        "    (\"organism\", \"visual_comfort\"),\n",
        "    (\"organism\", \"sense_of_order\"),\n",
        "    (\"organism\", \"preference_score\"),\n",
        "    (\"response\", \"visual_saliency\"),\n",
        "    (\"response\", \"attention_attraction\"),\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knVrepn61ydc",
        "outputId": "b75c8bb7-4ca3-4b13-a6a1-3a8492e2e0d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FacadeSORDataset(Dataset):\n",
        "    \"\"\"\n",
        "    返回内容为：\n",
        "    - concat_img: frame_1/frame_2/frame_3 横向拼接后的图片\n",
        "    - frame2_img: 单独的 frame_2\n",
        "    - y: JSON 中的 S-O-R 标签（8 维）\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir, transform=None):\n",
        "        self.base_dir = base_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get all folders and filter out checkpoint and hidden directories\n",
        "        all_items = os.listdir(base_dir)\n",
        "        self.folders = sorted(\n",
        "            d for d in all_items\n",
        "            if os.path.isdir(os.path.join(base_dir, d))\n",
        "            and not d.startswith('.')  # Skip hidden folders like .ipynb_checkpoints\n",
        "            and d != '__pycache__'      # Skip Python cache\n",
        "        )\n",
        "\n",
        "        # Validate folders have required files\n",
        "        valid_folders = []\n",
        "        for folder in self.folders:\n",
        "            folder_path = os.path.join(base_dir, folder)\n",
        "            required_files = [\"frame_1.jpg\", \"frame_2.jpg\", \"frame_3.jpg\", JSON_NAME]\n",
        "            if all(os.path.exists(os.path.join(folder_path, f)) for f in required_files):\n",
        "                valid_folders.append(folder)\n",
        "            else:\n",
        "                print(f\"Warning: Skipping folder '{folder}' - missing required files\")\n",
        "\n",
        "        self.folders = valid_folders\n",
        "        print(f\"Found {len(self.folders)} valid folders.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folders)\n",
        "\n",
        "    def _load_label(self, json_path):\n",
        "        try:\n",
        "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "            labels = [float(data[group][key]) for group, key in LABEL_KEYS]\n",
        "            return torch.tensor(labels, dtype=torch.float32)\n",
        "        except (FileNotFoundError, KeyError, ValueError) as e:\n",
        "            raise RuntimeError(f\"Error loading labels from {json_path}: {e}\")\n",
        "\n",
        "    def _load_concat(self, f1, f2, f3):\n",
        "        try:\n",
        "            img1 = Image.open(f1).convert(\"RGB\")\n",
        "            img2 = Image.open(f2).convert(\"RGB\")\n",
        "            img3 = Image.open(f3).convert(\"RGB\")\n",
        "\n",
        "            w, h = img1.size\n",
        "            concat_img = Image.new(\"RGB\", (w * 3, h))\n",
        "            concat_img.paste(img1, (0, 0))\n",
        "            concat_img.paste(img2, (w, 0))\n",
        "            concat_img.paste(img3, (2 * w, 0))\n",
        "            return concat_img\n",
        "        except FileNotFoundError as e:\n",
        "            raise RuntimeError(f\"Error loading images: {e}\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_name = self.folders[idx]\n",
        "        folder_path = os.path.join(self.base_dir, folder_name)\n",
        "\n",
        "        f1 = os.path.join(folder_path, \"frame_1.jpg\")\n",
        "        f2 = os.path.join(folder_path, \"frame_2.jpg\")\n",
        "        f3 = os.path.join(folder_path, \"frame_3.jpg\")\n",
        "        json_path = os.path.join(folder_path, JSON_NAME)\n",
        "\n",
        "        # Load images\n",
        "        concat_img = self._load_concat(f1, f2, f3)\n",
        "        frame2_img = Image.open(f2).convert(\"RGB\")\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform is not None:\n",
        "            concat_img = self.transform(concat_img)\n",
        "            frame2_img = self.transform(frame2_img)\n",
        "\n",
        "        # Load labels\n",
        "        y = self._load_label(json_path)\n",
        "\n",
        "        return concat_img, frame2_img, y"
      ],
      "metadata": {
        "id": "K_gNKYHy2IG9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Center-Aware Model"
      ],
      "metadata": {
        "id": "_ZoY9q7p4vXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CenterAwareConcatModel(nn.Module):\n",
        "\n",
        "    def __init__(self, backbone_name=\"resnet18\", num_outputs=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # --- Backbone: ResNet18 ---\n",
        "        backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "        in_features = backbone.fc.in_features\n",
        "        backbone.fc = nn.Identity()\n",
        "\n",
        "        # 共享参数\n",
        "        self.backbone = backbone\n",
        "        self.backbone_center = backbone\n",
        "\n",
        "        # MLP head\n",
        "        self.reg_head = nn.Sequential(\n",
        "            nn.Linear(in_features * 2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, concat_img, frame2_img):\n",
        "\n",
        "        f_concat = self.backbone(concat_img)\n",
        "        f_center = self.backbone_center(frame2_img)\n",
        "\n",
        "        fused = torch.cat([f_center, f_concat], dim=1)\n",
        "        out = self.reg_head(fused)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "acCepLpz4u6e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform + DataLoader"
      ],
      "metadata": {
        "id": "Ok7n87h14zNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset = FacadeSORDataset(BASE_DIR, transform=transform)\n",
        "\n",
        "val_size = int(len(dataset) * VAL_RATIO)\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS)\n",
        "\n",
        "print(f\"Train: {train_size}, Val: {val_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXhwVP9t4x04",
        "outputId": "8cc9a71b-6d3e-4975-94da-f49fb0324955"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping folder '9' - missing required files\n",
            "Found 99 valid folders.\n",
            "Train: 80, Val: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "Ew8kzQoD41PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CenterAwareConcatModel(num_outputs=len(LABEL_KEYS)).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "def run_epoch(loader, training=True):\n",
        "    model.train() if training else model.eval()\n",
        "    total_loss = 0\n",
        "    n = 0\n",
        "\n",
        "    for concat_img, frame2_img, targets in loader:\n",
        "        concat_img = concat_img.to(device)\n",
        "        frame2_img = frame2_img.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        if training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(training):\n",
        "            preds = model(concat_img, frame2_img)\n",
        "            loss = criterion(preds, targets)\n",
        "            if training:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * concat_img.size(0)\n",
        "        n += concat_img.size(0)\n",
        "\n",
        "    return total_loss / n\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss = run_epoch(train_loader, True)\n",
        "    val_loss   = run_epoch(val_loader, False)\n",
        "    print(f\"Epoch {epoch} | Train {train_loss:.4f} | Val {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fefh1yz240aO",
        "outputId": "6612caf1-752d-44b4-9964-44b81ab881fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 152MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train 37.9079 | Val 29.1669\n",
            "Epoch 2 | Train 21.2232 | Val 13.4033\n",
            "Epoch 3 | Train 8.6400 | Val 4.1868\n",
            "Epoch 4 | Train 2.1780 | Val 1.1153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save"
      ],
      "metadata": {
        "id": "Lydu_VtK436M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"checkpoints/sor_center_model.pth\")\n",
        "print(\"Model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlisVEMd43pU",
        "outputId": "a72fb290-6a1e-49fb-82cd-a781aceaa2a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivCSb3zI-FQs",
        "outputId": "de0f5ef7-b642-498d-bf9c-98bd12dc4e98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch.onnx\n",
            "  Downloading torch_onnx-0.1.25-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.12/dist-packages (from torch.onnx) (2.8.0+cu126)\n",
            "Collecting onnxscript>=0.1.0.dev20240831 (from torch.onnx)\n",
            "  Downloading onnxscript-0.5.7.dev20251119-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting onnx>=1.16 (from torch.onnx)\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from torch.onnx) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from torch.onnx) (25.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->torch.onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->torch.onnx) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->torch.onnx) (0.5.3)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript>=0.1.0.dev20240831->torch.onnx)\n",
            "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->torch.onnx) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1->torch.onnx) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1->torch.onnx) (3.0.3)\n",
            "Downloading torch_onnx-0.1.25-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.6/81.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.5.7.dev20251119-py3-none-any.whl (692 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.7/692.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx_ir, onnxscript, torch.onnx\n",
            "Successfully installed onnx-1.19.1 onnx_ir-0.1.12 onnxscript-0.5.7.dev20251119 torch.onnx-0.1.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONNX export"
      ],
      "metadata": {
        "id": "hbAvI1sU5ZKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ONNX Export =====\n",
        "\n",
        "import torch.onnx\n",
        "\n",
        "# 你模型的输出维度（8 个标签）\n",
        "NUM_OUTPUTS = len(LABEL_KEYS)   # 你前面定义过 LABEL_KEYS\n",
        "\n",
        "# 重新构建模型（必须和训练时完全一致）\n",
        "export_model = CenterAwareConcatModel(num_outputs=NUM_OUTPUTS)\n",
        "export_model.load_state_dict(torch.load(\"checkpoints/sor_center_model.pth\", map_location=\"cpu\"))\n",
        "export_model.eval()\n",
        "\n",
        "# 准备 dummy inputs（形状必须和真实推理时一样）\n",
        "dummy_concat = torch.randn(1, 3, 224, 224, requires_grad=False)\n",
        "dummy_frame2 = torch.randn(1, 3, 224, 224, requires_grad=False)\n",
        "\n",
        "# 导出 ONNX 模型\n",
        "torch.onnx.export(\n",
        "    export_model,\n",
        "    (dummy_concat, dummy_frame2),         # 2 inputs\n",
        "    \"facade_sor.onnx\",                   # 导出的文件名\n",
        "    input_names=[\"concat_img\", \"frame2_img\"],\n",
        "    output_names=[\"scores\"],\n",
        "    dynamic_axes=None,                   # 固定 batch=1，Grasshopper 用这个更稳\n",
        "    opset_version=17                     # 推荐 ONNX Opset\n",
        ")\n",
        "\n",
        "print(\"ONNX 模型导出成功: facade_sor.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGmexnyl5af4",
        "outputId": "3d397e48-4130-490a-9f48-4998bc963e83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1702073711.py:18: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX 模型导出成功: facade_sor.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test** torch model"
      ],
      "metadata": {
        "id": "YBAUptjW46bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one(idx):\n",
        "    folder = os.path.join(BASE_DIR, str(idx))\n",
        "    f1 = os.path.join(folder, \"frame_1.jpg\")\n",
        "    f2 = os.path.join(folder, \"frame_2.jpg\")\n",
        "    f3 = os.path.join(folder, \"frame_3.jpg\")\n",
        "\n",
        "    concat_img = dataset._load_concat(f1, f2, f3)\n",
        "    frame2_img = Image.open(f2).convert(\"RGB\")\n",
        "\n",
        "    concat_img = transform(concat_img).unsqueeze(0).to(device)\n",
        "    frame2_img = transform(frame2_img).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(concat_img, frame2_img)[0].cpu().numpy().tolist()\n",
        "\n",
        "    result = {}\n",
        "    for (group, key), val in zip(LABEL_KEYS, pred):\n",
        "        result.setdefault(group, {})\n",
        "        result[group][key] = float(val)\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "ihJUFZAA459Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_one(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Kde5TTHUEAHv",
        "outputId": "6614092c-eddb-4f7e-b4b2-f6c10ab3ff61"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict_one' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3543891204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_one' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test ONNX model"
      ],
      "metadata": {
        "id": "PLpPr9tc8lyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQTK2Rob_rV8",
        "outputId": "ccf8f623-f2f8-40d2-e227-4a2148fd40c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model_inference_onnx import FacadeScoringEngineONNX\n",
        "\n",
        "engine = FacadeScoringEngineONNX(\"facade_sor.onnx\")\n",
        "\n",
        "result = engine.predict(\"frame_1.jpg\", \"frame_2.jpg\", \"frame_3.jpg\")\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uIEhu9R8oIp",
        "outputId": "ae736f6e-7399-4b1f-d5ae-3a0cddf9f7b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'stimulus': {'composition_and_proportion': 3.3126060962677, 'material_and_details': 2.7733500003814697, 'color_harmony': 4.18727970123291}, 'organism': {'visual_comfort': 4.167214870452881, 'sense_of_order': 3.7930731773376465, 'preference_score': 3.810302257537842}, 'response': {'visual_saliency': 3.0102109909057617, 'attention_attraction': 4.1726603507995605}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQGu-5rMEBEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}